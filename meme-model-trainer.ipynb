{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Meme Image Classifier Trainer with Model Upload to Cloud Storage\n#### Overview\nThis is an end to end model trainer for creating an image classifier for memes. Once a model is trained it is uploaded to Azure cloud storage. The following is the general flow of this trainer:\n\n1. Meme titles are pulled using the imgflip api to get a list of meme titles.\n2. This list is then used to create a Bing image search for each meme that returns a list of image URLs to be downloaded for training. \n3. Finally the training is run and the model is saved to a cloud storage to be pulled in by another service.\n\nThis notebook is run on a cadence so that a consumer of the model can pull in the latest model at any given point from cloud storage.\n\nThe model is pretty good at guessing any meme seen in the titles list, but being reliant on the imgflip api caps what is seen. The api is supposed to return the top 100 or so memes that are popular on the site, but this appears to be somewhat hit or miss in testing.\n\nTraining was based around the FastAi library and using resnet18.\n\n---\n#### Notebook Setup\n\nThe following os vars must be set to use Azure services:\n```\nAZURE_SEARCH_KEY\nAZURE_STORAGE_CONNECTION_STRING\nSTORAGE_SHARE_NAME\n```\nThe image search is can return a flexable number of images by setting `TRAINING_DATA_SIZE` below (with a max of 150 imgs per search).\n\nThis notebook is more or less agnostic to what service it is run on, however anything that is specific to Kaggle should be tagged with the comment `only for Kaggle`.","metadata":{}},{"cell_type":"code","source":"!pip install --user torch==1.9.0 torchvision==0.10.0 torchaudio==0.9.0 torchtext==0.10.0 # only for Kaggle\n\nimport pandas as pd\nimport sys\nimport time\nimport requests\nimport urllib.request\nfrom PIL import Image\nfrom fastai.vision.all import *\nfrom pandas.api.types import CategoricalDtype\nfrom pathlib import Path\n\n\n\nfrom kaggle_secrets import UserSecretsClient # only for Kaggle\nuser_secrets = UserSecretsClient()\n\nsecret_key = user_secrets.get_secret(\"AZURE_SEARCH_KEY\")\n\n\napi_url = \"https://api.imgflip.com/get_memes\"\nOUTPUT_DIR = \"./\"\nTRAINING_DATA_DIR = \"meme_training_data\"\nTRAINING_DATA_PATH = OUTPUT_DIR+TRAINING_DATA_DIR\nTRAINING_DATA_SIZE = 40\n\n# create a directory if it doesn't exist\nif not os.path.exists(TRAINING_DATA_PATH):\n    os.makedirs(TRAINING_DATA_PATH)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-05T18:28:14.962279Z","iopub.execute_input":"2022-05-05T18:28:14.962871Z","iopub.status.idle":"2022-05-05T18:29:32.020875Z","shell.execute_reply.started":"2022-05-05T18:28:14.962722Z","shell.execute_reply":"2022-05-05T18:29:32.019847Z"},"_kg_hide-output":true,"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"#### Helper Functions","metadata":{}},{"cell_type":"code","source":"!pip install azure-cognitiveservices-search-imagesearch\n\nfrom azure.cognitiveservices.search.imagesearch import ImageSearchClient as api\nfrom msrest.authentication import CognitiveServicesCredentials as auth\n\ndef search_images_bing(key, term, min_sz=128, max_images=150):    \n     params = {'q':term, 'count':max_images, 'min_height':min_sz, 'min_width':min_sz}\n     headers = {\"Ocp-Apim-Subscription-Key\":key}\n     search_url = \"https://api.bing.microsoft.com/v7.0/images/search\"\n     response = requests.get(search_url, headers=headers, params=params)\n     response.raise_for_status()\n     search_results = response.json()\n     return L(search_results['value'])\n    \ndef get_image(row) -> str:\n    url = row['url']\n    name = row['name']\n    filename = name.lower().replace(' ', '_') + '.jpg'\n    r = requests.get(url)\n    with open(OUTPUT_DIR+filename, 'wb') as outfile:\n        outfile.write(r.content)\n    return filename\n\ndef get_training_image_from_bing(row):\n    search_term = row['name'] + 'meme'\n    return search_images_bing(secret_key, search_term, max_images=TRAINING_DATA_SIZE)\n\ndef get_training_data(row):\n    path = Path(TRAINING_DATA_PATH + '/' + row['name'].lower().replace(' ', '_'))\n    if not path.exists():\n        path.mkdir()\n    results = get_training_image_from_bing(row)\n    results_content_urls = results.attrgot('contentUrl')\n    download_images(path, urls=results_content_urls)\n    return results_content_urls","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:30:06.645632Z","iopub.execute_input":"2022-05-05T18:30:06.645971Z","iopub.status.idle":"2022-05-05T18:30:21.034362Z","shell.execute_reply.started":"2022-05-05T18:30:06.645929Z","shell.execute_reply":"2022-05-05T18:30:21.033343Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"---\n## Get Meme Types From API","metadata":{}},{"cell_type":"code","source":"response = requests.get(api_url)\nresponse.json()['data']['memes'][0]\n\n# Load response into dataframe\nmeme_df = pd.DataFrame(response.json()['data']['memes'])\n\npd.set_option('display.max_columns', None)\nmeme_df","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:30:30.875633Z","iopub.execute_input":"2022-05-05T18:30:30.875992Z","iopub.status.idle":"2022-05-05T18:30:31.063829Z","shell.execute_reply.started":"2022-05-05T18:30:30.875956Z","shell.execute_reply":"2022-05-05T18:30:31.062907Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"---\n## Collect Training Data\nFor each meme type run a bing image search and download the images for training data.","metadata":{}},{"cell_type":"code","source":"print('Downloading training data. This might take a few minutes...')\nmeme_df['example_urls'] = meme_df.apply(get_training_data, axis=1)\nmeme_csv_path = OUTPUT_DIR+'memes.csv'\nmeme_df.to_csv(meme_csv_path)\nprint('Training data downloads completed.')\nprint('Saving df to ' + meme_csv_path)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:30:41.836110Z","iopub.execute_input":"2022-05-05T18:30:41.836523Z","iopub.status.idle":"2022-05-05T18:38:15.340168Z","shell.execute_reply.started":"2022-05-05T18:30:41.836464Z","shell.execute_reply":"2022-05-05T18:38:15.338991Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# clean any failed state files\nfns = get_image_files(TRAINING_DATA_PATH)\nfailed = verify_images(fns)\nfailed.map(Path.unlink);","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:38:31.526952Z","iopub.execute_input":"2022-05-05T18:38:31.527244Z","iopub.status.idle":"2022-05-05T18:38:59.174951Z","shell.execute_reply.started":"2022-05-05T18:38:31.527212Z","shell.execute_reply":"2022-05-05T18:38:59.173785Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"---\n## Build model\nNow that we have training data downloaded we can start to build out our actual ml model.","metadata":{}},{"cell_type":"code","source":"memes_data_block = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms()\n    )\ndls = memes_data_block.dataloaders(TRAINING_DATA_PATH)\n\ndls.valid.show_batch(max_n=8, nrows=1)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-05T18:39:03.841322Z","iopub.execute_input":"2022-05-05T18:39:03.841636Z","iopub.status.idle":"2022-05-05T18:39:09.100753Z","shell.execute_reply.started":"2022-05-05T18:39:03.841601Z","shell.execute_reply":"2022-05-05T18:39:09.099952Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"learn = cnn_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(4)\n\nlearn.export()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:39:21.389628Z","iopub.execute_input":"2022-05-05T18:39:21.390120Z","iopub.status.idle":"2022-05-05T18:44:27.701577Z","shell.execute_reply.started":"2022-05-05T18:39:21.390084Z","shell.execute_reply":"2022-05-05T18:44:27.700521Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Export Model and Save Offline\nUses Azure [Share Service](https://docs.microsoft.com/en-us/azure/storage/files/storage-python-how-to-use-file-storage?tabs=python) for persistant storage.","metadata":{}},{"cell_type":"code","source":"!pip install azure-storage-file-share\n\nfrom azure.core.exceptions import (\n    ResourceExistsError,\n    ResourceNotFoundError\n)\n\nfrom azure.storage.fileshare import (\n    ShareServiceClient,\n    ShareClient,\n    ShareDirectoryClient,\n    ShareFileClient\n)\n\nSTORAGE_CONNECTION_STRING = user_secrets.get_secret(\"AZURE_STORAGE_CONNECTION_STRING\")\nSTORAGE_SHARE_NAME = user_secrets.get_secret(\"STORAGE_SHARE_NAME\")\n\ntry:\n    # Create a ShareClient from a connection string\n    share_client = ShareClient.from_connection_string(STORAGE_CONNECTION_STRING, STORAGE_SHARE_NAME)\n    print(\"Creating share:\", STORAGE_SHARE_NAME)\n    share_client.create_share()\nexcept ResourceExistsError as ex:\n    print(\"Share already exists moving to store ->\")\n\ndef upload_to_cloud_storage(filename):\n    local_file_path = OUTPUT_DIR + filename\n    try:\n        source_file = open(local_file_path, \"rb\")\n        data = source_file.read()\n\n        # Create a ShareFileClient from a connection string\n        file_client = ShareFileClient.from_connection_string(STORAGE_CONNECTION_STRING, STORAGE_SHARE_NAME, filename)\n\n        print(\"Uploading to:\", STORAGE_SHARE_NAME + \"/\" + filename)\n        file_client.upload_file(data)\n\n    except ResourceExistsError as ex:\n        print(\"ResourceExistsError:\", ex.message)\n\n    except ResourceNotFoundError as ex:\n        print(\"ResourceNotFoundError:\", ex.message)\n\nfilename = 'export.pkl'\nupload_to_cloud_storage(filename)\nupload_to_cloud_storage('memes.csv')\nprint('Model uploaded')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-05T19:03:43.924411Z","iopub.execute_input":"2022-05-05T19:03:43.924728Z","iopub.status.idle":"2022-05-05T19:04:12.564363Z","shell.execute_reply.started":"2022-05-05T19:03:43.924695Z","shell.execute_reply":"2022-05-05T19:04:12.563304Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"---\n## Manual Testing Model","metadata":{}},{"cell_type":"code","source":"# from fastai.vision.widgets import *\n# btn_upload = widgets.FileUpload()\n# btn_upload","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:50:20.495734Z","iopub.execute_input":"2022-05-05T18:50:20.496736Z","iopub.status.idle":"2022-05-05T18:50:20.515040Z","shell.execute_reply.started":"2022-05-05T18:50:20.496701Z","shell.execute_reply":"2022-05-05T18:50:20.513584Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# img = PILImage.create(btn_upload.data[-1])\n# out_pl = widgets.Output()\n# out_pl.clear_output()\n# with out_pl: display(img.to_thumb(128,128))\n    \n# pred,pred_idx,probs = learn.predict(img)\n# print(f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}')\n# out_pl\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:50:27.164613Z","iopub.execute_input":"2022-05-05T18:50:27.165259Z","iopub.status.idle":"2022-05-05T18:50:27.262892Z","shell.execute_reply.started":"2022-05-05T18:50:27.165222Z","shell.execute_reply":"2022-05-05T18:50:27.261583Z"},"trusted":true},"execution_count":17,"outputs":[]}]}